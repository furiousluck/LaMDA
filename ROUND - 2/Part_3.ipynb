{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import spacy"
      ],
      "metadata": {
        "id": "4YzpODJcwyUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constituent Path"
      ],
      "metadata": {
        "id": "UROimv_Gw18l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liGTdqOjq7X-"
      },
      "outputs": [],
      "source": [
        "def find_constituent_path(text, entity1, entity2):\n",
        "    # Parse the text into a tree structure\n",
        "    tree = nltk.Tree.fromstring(text)\n",
        "\n",
        "    # Find the two entities in the tree and extract their corresponding subtrees\n",
        "    entity1_subtree = tree.subtrees(lambda t: t.label() == entity1)[0]\n",
        "    entity2_subtree = tree.subtrees(lambda t: t.label() == entity2)[0]\n",
        "\n",
        "    # Find the lowest common ancestor (LCA) of the two entities\n",
        "    lca = tree.common_ancestor(entity1_subtree, entity2_subtree)\n",
        "\n",
        "    # Extract the constituent path by traversing the tree from the LCA to each of the two entities\n",
        "    path = []\n",
        "    current_node = lca\n",
        "    while current_node != entity1_subtree:\n",
        "        path.append(current_node.label())\n",
        "        current_node = current_node[0]\n",
        "    path.append(entity1)\n",
        "    current_node = lca\n",
        "    while current_node != entity2_subtree:\n",
        "        path.append(current_node.label())\n",
        "        current_node = current_node[-1]\n",
        "    path.append(entity2)\n",
        "\n",
        "    return path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words"
      ],
      "metadata": {
        "id": "8kjglyt0w7Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_bag_of_words(text, entity1, entity2):\n",
        "    # Tokenize the text into words\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stop words and punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word not in stop_words and word.isalpha()]\n",
        "\n",
        "    # Find the indices of the two entities\n",
        "    entity1_index = words.index(entity1)\n",
        "    entity2_index = words.index(entity2)\n",
        "\n",
        "    # Extract the bag of words between the two entities\n",
        "    bag_of_words = words[entity1_index + 1:entity2_index]\n",
        "\n",
        "    return bag_of_words\n"
      ],
      "metadata": {
        "id": "tgV5s139xBBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntactic Structure"
      ],
      "metadata": {
        "id": "UatcSOp5xDMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_syntactic_structure(text, entity1, entity2):\n",
        "    # Parse the text with the language model\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Initialize a list to store the syntactic structures\n",
        "    structures = []\n",
        "\n",
        "    # Iterate over the entities and the dependencies between them\n",
        "    for entity in doc:\n",
        "        if entity.text == entity1:\n",
        "            for child in entity.children:\n",
        "                if child.text == entity2:\n",
        "                    structures.append(child.dep_)\n",
        "\n",
        "    return structures"
      ],
      "metadata": {
        "id": "MW0gZ0AmxUk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}